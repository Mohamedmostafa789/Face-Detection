{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e3a435-42cb-4b7c-9a55-f7e23e094a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from tkinter import Label, Button, Text\n",
    "from PIL import Image, ImageTk\n",
    "from deepface import DeepFace\n",
    "\n",
    "# Load Models\n",
    "def load_models():\n",
    "    proto_path_gender = \"gender_deploy.prototxt\"\n",
    "    model_path_gender = \"gender_net.caffemodel\"\n",
    "    proto_path_age = \"age_deploy.prototxt\"\n",
    "    model_path_age = \"age_net.caffemodel\"\n",
    "\n",
    "    try:\n",
    "        gender_net = cv2.dnn.readNetFromCaffe(proto_path_gender, model_path_gender)\n",
    "        age_net = cv2.dnn.readNetFromCaffe(proto_path_age, model_path_age)\n",
    "    except cv2.error as e:\n",
    "        print(f\"❌ Error loading models: {e}\")\n",
    "        return None, None  \n",
    "\n",
    "    if gender_net.empty() or age_net.empty():\n",
    "        print(\"❌ One or more models failed to load. Check file paths!\")\n",
    "        return None, None  \n",
    "\n",
    "    return gender_net, age_net\n",
    "\n",
    "# Face detection and prediction\n",
    "def detect_faces_and_predict(frame, gender_net, age_net):\n",
    "    if gender_net is None or age_net is None:\n",
    "        return []  \n",
    "\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        return []  \n",
    "\n",
    "    results = []\n",
    "    age_ranges = [\"(0-2)\", \"(4-6)\", \"(8-12)\", \"(15-20)\", \"(25-32)\", \"(38-43)\", \"(48-53)\", \"(60-100)\"]\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face = frame[y:y+h, x:x+w]\n",
    "\n",
    "        # Ensure valid face before processing\n",
    "        if face.shape[0] < 30 or face.shape[1] < 30:\n",
    "            continue  # Skip small faces\n",
    "\n",
    "        face_blob = cv2.dnn.blobFromImage(face, scalefactor=1.0, size=(227, 227), \n",
    "                                          mean=(78.426, 87.769, 114.896), \n",
    "                                          swapRB=False, crop=False)\n",
    "\n",
    "        # Gender Prediction\n",
    "        gender_net.setInput(face_blob)\n",
    "        gender_preds = gender_net.forward()\n",
    "        gender_confidence = max(gender_preds[0]) * 100  \n",
    "        gender = \"Male\" if gender_preds[0][0] > gender_preds[0][1] else \"Female\"\n",
    "\n",
    "        # Age Prediction\n",
    "        age_net.setInput(face_blob)\n",
    "        age_preds = age_net.forward()\n",
    "        age_idx = np.argmax(age_preds[0])\n",
    "        age_confidence = age_preds[0][age_idx] * 100  \n",
    "        age = age_ranges[age_idx]\n",
    "\n",
    "        # Emotion Prediction using DeepFace\n",
    "        temp_path = \"temp_face.jpg\"\n",
    "        cv2.imwrite(temp_path, face)\n",
    "        \n",
    "        emotion = \"Unknown\"\n",
    "        emotion_confidence = 0\n",
    "        \n",
    "        try:\n",
    "            analysis = DeepFace.analyze(temp_path, actions=[\"emotion\"], enforce_detection=False)\n",
    "            if analysis and isinstance(analysis, list):\n",
    "                emotion = analysis[0][\"dominant_emotion\"]\n",
    "                emotion_confidence = analysis[0][\"emotion\"].get(emotion, 0)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ DeepFace Emotion Detection Error: {e}\")\n",
    "\n",
    "        os.remove(temp_path)  # Clean up temp file\n",
    "\n",
    "        results.append(((x, y, w, h), gender, gender_confidence, age, age_confidence, emotion, emotion_confidence))\n",
    "\n",
    "    return results\n",
    "\n",
    "# Update Frame in Real-Time\n",
    "def update_frame():\n",
    "    global cap, photo_label\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        results = detect_faces_and_predict(frame, gender_net, age_net)\n",
    "        save_results(results)  # Save results in CSV/JSON\n",
    "        \n",
    "        for ((x, y, w, h), gender, gender_conf, age, age_conf, emotion, emotion_conf) in results:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            text = f\"{gender} ({gender_conf:.1f}%), {age} ({age_conf:.1f}%), {emotion} ({emotion_conf:.1f}%)\"\n",
    "            cv2.putText(frame, text, (x, y-10), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "        \n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(frame)\n",
    "        img = ImageTk.PhotoImage(img)\n",
    "        photo_label.imgtk = img\n",
    "        photo_label.configure(image=img)\n",
    "    \n",
    "    root.after(10, update_frame)\n",
    "\n",
    "# Save results to CSV/JSON\n",
    "def save_results(results):\n",
    "    csv_filename = \"detection_results.csv\"\n",
    "    json_filename = \"detection_results.json\"\n",
    "\n",
    "    data = []\n",
    "    for ((x, y, w, h), gender, gender_conf, age, age_conf, emotion, emotion_conf) in results:\n",
    "        data.append({\n",
    "            \"gender\": gender,\n",
    "            \"gender_confidence\": f\"{gender_conf:.1f}%\",\n",
    "            \"age\": age,\n",
    "            \"age_confidence\": f\"{age_conf:.1f}%\",\n",
    "            \"emotion\": emotion,\n",
    "            \"emotion_confidence\": f\"{emotion_conf:.1f}%\"\n",
    "        })\n",
    "\n",
    "    # Save to CSV\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(csv_filename, mode='a', index=False, header=not os.path.exists(csv_filename))\n",
    "\n",
    "    # Save to JSON\n",
    "    with open(json_filename, \"w\") as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "# Detect and Show Results in GUI\n",
    "def detect_and_show_results():\n",
    "    global result_text, cap\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        results = detect_faces_and_predict(frame, gender_net, age_net)\n",
    "        save_results(results)  # Save to file\n",
    "        result_text.delete(1.0, tk.END)\n",
    "        \n",
    "        for idx, ((x, y, w, h), gender, gender_conf, age, age_conf, emotion, emotion_conf) in enumerate(results):\n",
    "            result_text.insert(tk.END, f\"Person {idx+1}:\\n\")\n",
    "            result_text.insert(tk.END, f\"  Gender: {gender} ({gender_conf:.1f}%)\\n\")\n",
    "            result_text.insert(tk.END, f\"  Age Range: {age} ({age_conf:.1f}%)\\n\")\n",
    "            result_text.insert(tk.END, f\"  Emotion: {emotion} ({emotion_conf:.1f}%)\\n\\n\")\n",
    "\n",
    "# Load models\n",
    "gender_net, age_net = load_models()\n",
    "\n",
    "if gender_net is None or age_net is None:\n",
    "    print(\"❌ Models failed to load. Exiting program.\")\n",
    "    exit()\n",
    "\n",
    "# Setup GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"Age, Gender & Emotion Detection with Confidence Scores\")\n",
    "\n",
    "photo_label = Label(root)\n",
    "photo_label.pack()\n",
    "\n",
    "btn_detect = Button(root, text=\"Detect\", command=detect_and_show_results)\n",
    "btn_detect.pack()\n",
    "\n",
    "result_text = Text(root, height=10, width=60)\n",
    "result_text.pack()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "update_frame()\n",
    "\n",
    "root.mainloop()\n",
    "\n",
    "# Release resources only after GUI closes\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ebb5fd-f58e-4222-8a6a-78f6b7fb81e5",
   "metadata": {},
   "source": [
    "### The system supports both USB webcams and IP camera streams (such as an iPhone camera) and features a Tkinter-based GUI for ease of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226003a8-5647-4ce6-a85a-7091308b6810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from tkinter import Label, Button, Text\n",
    "from PIL import Image, ImageTk\n",
    "from deepface import DeepFace\n",
    "\n",
    "# iPhone Stream Configuration\n",
    "ip = \"192.168.43.2\"\n",
    "port = \"4747\"\n",
    "username = \"admin\"\n",
    "password = \"admin\"\n",
    "url = f\"http://{username}:{password}@{ip}:{port}/video\"\n",
    "\n",
    "# Load Models\n",
    "def load_models():\n",
    "    proto_path_gender = \"gender_deploy.prototxt\"\n",
    "    model_path_gender = \"gender_net.caffemodel\"\n",
    "    proto_path_age = \"age_deploy.prototxt\"\n",
    "    model_path_age = \"age_net.caffemodel\"\n",
    "\n",
    "    try:\n",
    "        gender_net = cv2.dnn.readNetFromCaffe(proto_path_gender, model_path_gender)\n",
    "        age_net = cv2.dnn.readNetFromCaffe(proto_path_age, model_path_age)\n",
    "    except cv2.error as e:\n",
    "        print(f\"❌ Error loading models: {e}\")\n",
    "        return None, None  \n",
    "\n",
    "    if gender_net.empty() or age_net.empty():\n",
    "        print(\"❌ One or more models failed to load. Check file paths!\")\n",
    "        return None, None  \n",
    "\n",
    "    return gender_net, age_net\n",
    "\n",
    "# Face detection and prediction\n",
    "def detect_faces_and_predict(frame, gender_net, age_net):\n",
    "    if gender_net is None or age_net is None:\n",
    "        return []  \n",
    "\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        return []  \n",
    "\n",
    "    results = []\n",
    "    age_ranges = [\"(0-2)\", \"(4-6)\", \"(8-12)\", \"(15-20)\", \"(25-32)\", \"(38-43)\", \"(48-53)\", \"(60-100)\"]\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face = frame[y:y+h, x:x+w]\n",
    "\n",
    "        # Ensure valid face before processing\n",
    "        if face.shape[0] < 30 or face.shape[1] < 30:\n",
    "            continue  # Skip small faces\n",
    "\n",
    "        face_blob = cv2.dnn.blobFromImage(face, scalefactor=1.0, size=(227, 227), \n",
    "                                          mean=(78.426, 87.769, 114.896), \n",
    "                                          swapRB=False, crop=False)\n",
    "\n",
    "        # Gender Prediction\n",
    "        gender_net.setInput(face_blob)\n",
    "        gender_preds = gender_net.forward()\n",
    "        gender_confidence = max(gender_preds[0]) * 100  \n",
    "        gender = \"Male\" if gender_preds[0][0] > gender_preds[0][1] else \"Female\"\n",
    "\n",
    "        # Age Prediction\n",
    "        age_net.setInput(face_blob)\n",
    "        age_preds = age_net.forward()\n",
    "        age_idx = np.argmax(age_preds[0])\n",
    "        age_confidence = age_preds[0][age_idx] * 100  \n",
    "        age = age_ranges[age_idx]\n",
    "\n",
    "        # Emotion Prediction using DeepFace\n",
    "        temp_path = \"temp_face.jpg\"\n",
    "        cv2.imwrite(temp_path, face)\n",
    "        \n",
    "        emotion = \"Unknown\"\n",
    "        emotion_confidence = 0\n",
    "        \n",
    "        try:\n",
    "            analysis = DeepFace.analyze(temp_path, actions=[\"emotion\"], enforce_detection=False)\n",
    "            if analysis and isinstance(analysis, list):\n",
    "                emotion = analysis[0][\"dominant_emotion\"]\n",
    "                emotion_confidence = analysis[0][\"emotion\"].get(emotion, 0)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ DeepFace Emotion Detection Error: {e}\")\n",
    "\n",
    "        os.remove(temp_path)  # Clean up temp file\n",
    "\n",
    "        results.append(((x, y, w, h), gender, gender_confidence, age, age_confidence, emotion, emotion_confidence))\n",
    "\n",
    "    return results\n",
    "\n",
    "# Update Frame in Real-Time\n",
    "def update_frame():\n",
    "    global cap, photo_label\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        results = detect_faces_and_predict(frame, gender_net, age_net)\n",
    "        save_results(results)  # Save results in CSV/JSON\n",
    "        \n",
    "        for ((x, y, w, h), gender, gender_conf, age, age_conf, emotion, emotion_conf) in results:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            text = f\"{gender} ({gender_conf:.1f}%), {age} ({age_conf:.1f}%), {emotion} ({emotion_conf:.1f}%)\"\n",
    "            cv2.putText(frame, text, (x, y-10), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "        \n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(frame)\n",
    "        img = ImageTk.PhotoImage(img)\n",
    "        photo_label.imgtk = img\n",
    "        photo_label.configure(image=img)\n",
    "    \n",
    "    root.after(10, update_frame)\n",
    "\n",
    "# Save results to CSV/JSON\n",
    "def save_results(results):\n",
    "    csv_filename = \"detection_results.csv\"\n",
    "    json_filename = \"detection_results.json\"\n",
    "\n",
    "    data = []\n",
    "    for ((x, y, w, h), gender, gender_conf, age, age_conf, emotion, emotion_conf) in results:\n",
    "        data.append({\n",
    "            \"gender\": gender,\n",
    "            \"gender_confidence\": f\"{gender_conf:.1f}%\",\n",
    "            \"age\": age,\n",
    "            \"age_confidence\": f\"{age_conf:.1f}%\",\n",
    "            \"emotion\": emotion,\n",
    "            \"emotion_confidence\": f\"{emotion_conf:.1f}%\"\n",
    "        })\n",
    "\n",
    "    # Save to CSV\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(csv_filename, mode='a', index=False, header=not os.path.exists(csv_filename))\n",
    "\n",
    "    # Save to JSON\n",
    "    with open(json_filename, \"w\") as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "# Detect and Show Results in GUI\n",
    "def detect_and_show_results():\n",
    "    global result_text, cap\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        results = detect_faces_and_predict(frame, gender_net, age_net)\n",
    "        save_results(results)  # Save to file\n",
    "        result_text.delete(1.0, tk.END)\n",
    "        \n",
    "        for idx, ((x, y, w, h), gender, gender_conf, age, age_conf, emotion, emotion_conf) in enumerate(results):\n",
    "            result_text.insert(tk.END, f\"Person {idx+1}:\\n\")\n",
    "            result_text.insert(tk.END, f\"  Gender: {gender} ({gender_conf:.1f}%)\\n\")\n",
    "            result_text.insert(tk.END, f\"  Age Range: {age} ({age_conf:.1f}%)\\n\")\n",
    "            result_text.insert(tk.END, f\"  Emotion: {emotion} ({emotion_conf:.1f}%)\\n\\n\")\n",
    "\n",
    "# Load models\n",
    "gender_net, age_net = load_models()\n",
    "\n",
    "if gender_net is None or age_net is None:\n",
    "    print(\"❌ Models failed to load. Exiting program.\")\n",
    "    exit()\n",
    "\n",
    "# Setup GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"Age, Gender & Emotion Detection with Confidence Scores\")\n",
    "\n",
    "photo_label = Label(root)\n",
    "photo_label.pack()\n",
    "\n",
    "btn_detect = Button(root, text=\"Detect\", command=detect_and_show_results)\n",
    "btn_detect.pack()\n",
    "\n",
    "result_text = Text(root, height=10, width=60)\n",
    "result_text.pack()\n",
    "\n",
    "# Connect to iPhone Video Stream\n",
    "cap = cv2.VideoCapture(url)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"❌ Failed to connect to iPhone video stream. Check IP, port, and app settings.\")\n",
    "    exit()\n",
    "\n",
    "update_frame()\n",
    "\n",
    "root.mainloop()\n",
    "\n",
    "# Release resources only after GUI closes\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f201764-5a80-40f7-9116-15b0227f82d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba26aead-be56-4dac-932a-2c2d3506b610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfd113a-6e3f-4a68-bfa0-7df8fc99ab58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c600e3c7-470a-41e4-930f-5dc4c01ea51d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdfa0b9-a0d6-45be-8197-6bc1ed27c89e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3696b0a-7d81-42bd-aa5a-23ac8c415fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f655bc43-42fb-44b8-ac16-370852868796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
